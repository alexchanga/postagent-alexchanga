{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "BzvZapTSRCE6"
      },
      "outputs": [],
      "source": [
        "%pip install -qU langchain langchain_openai langchain-core langgraph langchain-community psycopg[binary,pool]==3.2.6 langgraph-checkpoint-postgres langchain-elasticsearch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSjuHoSpRiqX"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "\n",
        "with open(\"/content/api_key.txt\") as archivo:\n",
        "  apikey = archivo.read()\n",
        "os.environ[\"OPENAI_API_KEY\"] = apikey\n",
        "\n",
        "\n",
        "uribd = \"postgresql://postgres:zVDM1%3DE%40EJ%2BYr%26D4@34.42.5.253:5432/postgres3?sslmode=disable\"\n",
        "\n",
        "\n",
        "elasticpws = \"eibzqumDfW3RuR-z1RtL\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "KgVfta9VR-K9"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_elasticsearch import ElasticsearchStore\n",
        "from psycopg_pool import ConnectionPool\n",
        "from langgraph.checkpoint.postgres import PostgresSaver\n",
        "from langgraph.prebuilt import create_react_agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "VvYdZKLGSUbm"
      },
      "outputs": [],
      "source": [
        "db_historial = ElasticsearchStore(\n",
        "        es_url=\"http://34.125.185.182:9200\",\n",
        "        es_user=\"elastic\",\n",
        "        es_password=\"eibzqumDfW3RuR-z1RtL\",\n",
        "        index_name=\"lg-postventa\",\n",
        "        embedding=OpenAIEmbeddings())\n",
        "\n",
        "# Herramienta RAG Historial\n",
        "retriever_Historial = db_historial.as_retriever()\n",
        "tool_rag_historial = retriever_Historial.as_tool(\n",
        "    name=\"historial_usuario\",\n",
        "    description=(\n",
        "      \"Consulta el historial de interacciones y pedidos del usuario.\"\n",
        "      \"Úsalo para personalizar recomendaciones y verificar el estado de productos entregados, devueltos, en tránsito o pendientes.\"\n",
        "  )\n",
        ")\n",
        "\n",
        "\n",
        "db_stock = ElasticsearchStore(\n",
        "        es_url=\"http://34.125.185.182:9200\",\n",
        "        es_user=\"elastic\",\n",
        "        es_password=\"eibzqumDfW3RuR-z1RtL\",\n",
        "        index_name=\"lg-prodstock\",\n",
        "        embedding=OpenAIEmbeddings())\n",
        "\n",
        "# Herramienta RAG Stock\n",
        "retriever_stock = db_stock.as_retriever()\n",
        "tool_rag_stock = retriever_stock.as_tool(\n",
        "    name=\"busqueda_productos\",\n",
        "    description=\"Consulta productos tecnológicos disponibles\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "EI3QiIMASc1d"
      },
      "outputs": [],
      "source": [
        "\n",
        "## Ejecutar solo la primera vez para crear automaticamente las tablas\n",
        "## [checkpoint_blobs, checkpoint_migrations, checkpoint_writes, checkpoints] en el esquema public\n",
        "#Variables de memoria\n",
        "connection_kwargs = {\n",
        "    \"autocommit\": True,\n",
        "    \"prepare_threshold\": 0,\n",
        "}\n",
        "# Inicializamos la memoria\n",
        "with ConnectionPool(\n",
        "    # Example configuration\n",
        "    conninfo=\"postgresql://postgres:zVDM1%3DE%40EJ%2BYr%26D4@34.42.5.253:5432/postgres3?sslmode=disable\",\n",
        "    max_size=20,\n",
        "    kwargs=connection_kwargs,\n",
        ") as pool:\n",
        "    checkpointer = PostgresSaver(pool)\n",
        "    checkpointer.setup()\n",
        "##  Eliminar esta celda luego de crear la memoria"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWoAv3coU3Am",
        "outputId": "85bd0ec4-eb1e-470a-c535-3fee011d834c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Hola\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "¡Hola! Gracias por comunicarte con soporte postventa. ¿En qué producto necesitas ayuda? ¿Es una laptop, PC, accesorio u otro dispositivo? Estoy aquí para asistirte en lo que necesites.\n"
          ]
        }
      ],
      "source": [
        "#Variables de memoria\n",
        "connection_kwargs = {\n",
        "    \"autocommit\": True,\n",
        "    \"prepare_threshold\": 0,\n",
        "}\n",
        "# Inicializamos la memoria\n",
        "with ConnectionPool(\n",
        "    # Example configuration\n",
        "    conninfo=\"postgresql://postgres:zVDM1%3DE%40EJ%2BYr%26D4@34.42.5.253:5432/postgres3?sslmode=disable\",\n",
        "    max_size=20,\n",
        "    kwargs=connection_kwargs,\n",
        ") as pool:\n",
        "    checkpointer = PostgresSaver(pool)\n",
        "\n",
        "    # Inicializamos el modelo sde recomienda el 4.1\n",
        "    model = ChatOpenAI(model=\"gpt-4.1-2025-04-14\")\n",
        "\n",
        "    # Agrupamos las herramientas\n",
        "    tolkit = [tool_rag_stock,tool_rag_historial]\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "            [\n",
        "                (\"system\",\n",
        "                \"\"\"\n",
        "                Eres un asistente postventa amable y eficiente, especializado en soporte de productos tecnológicos.\n",
        "                Utiliza únicamente las herramientas disponibles para responder y brindar información.\n",
        "                Si no cuentas con una herramienta específica para resolver una pregunta, infórmalo claramente e indica cómo puedes ayudar.\n",
        "\n",
        "                Tu objetivo es acompañar al cliente de forma empática, clara y resolutiva. Sigue estos pasos:\n",
        "\n",
        "                1. Saludo y contexto:\n",
        "                    - Saluda cordialmente y pregunta en qué producto necesita ayuda (ej. laptop, PC, accesorio).\n",
        "                    - Si ya lo menciona, agradece y pide más detalles del problema o consulta.\n",
        "\n",
        "                2. Verificación de compra:\n",
        "                    - Solicita el número de pedido o el correo con el que se realizó la compra para verificar la información.\n",
        "                    - Usa la herramienta `historial_usuario` para consultar el historial de pedidos y verificar el estado del producto.\n",
        "                    - Si el pedido ya fue entregado, verifica automáticamente si está dentro del plazo de 7 días desde la fecha de entrega (no es necesario preguntarle al cliente).\n",
        "\n",
        "                3. Diagnóstico o gestión:\n",
        "                    - Si es un problema técnico, ofrece pasos básicos de solución o sugiere contacto con soporte técnico si es necesario.\n",
        "                    - Si es una devolución o cambio:\n",
        "                        - Verifica si el producto solicitado para cambio está disponible en stock usando la herramienta `busqueda_productos`.\n",
        "                        - Si no hay stock, informa al cliente y ofrece alternativas de la misma categoría (otro modelo, reembolso o espera).\n",
        "                        - Si hay stock, explica las condiciones (ej. dentro de 7 días, producto sin uso) y el proceso.\n",
        "                    - Si es seguimiento de pedido, consulta el estado y proporciona la información.\n",
        "\n",
        "                4. Opciones de solución:\n",
        "                    - Ofrece alternativas claras (cambio, reembolso, reparación, seguimiento) según el caso y disponibilidad.\n",
        "                    - Prioriza sugerencias de productos de la misma categoría si el original no está disponible.\n",
        "\n",
        "                5. Confirmación de acción:\n",
        "                    - Resume lo acordado y pregunta si desea continuar con esa opción.\n",
        "\n",
        "                6. Cierre:\n",
        "                    - Agradece su paciencia y confianza.\n",
        "                    - Ofrece ayuda adicional si la necesita.\n",
        "                    - Despídete cordialmente.\n",
        "\n",
        "                Estilo:\n",
        "                    - Sé breve, empático y profesional.\n",
        "                    - Usa un tono cercano y resolutivo.\n",
        "                    - Evita tecnicismos a menos que el cliente los use.\n",
        "                    - Responde solo lo necesario para avanzar la conversación.\n",
        "                \"\"\"),\n",
        "                (\"human\", \"{messages}\"),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    #inicializamos el agente\n",
        "    agent_executor = create_react_agent(model, tolkit, checkpointer=checkpointer, prompt=prompt)\n",
        "\n",
        "\n",
        "    config = {\"configurable\": {\"thread_id\": \"mc0001\"}} ## el thread_id es el identificador de memoria\n",
        "    for step in agent_executor.stream(\n",
        "        {\"messages\": [HumanMessage(content=\"Hola\")]},\n",
        "        config,\n",
        "        stream_mode=\"values\",\n",
        "    ):\n",
        "      step[\"messages\"][-1].pretty_print()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
